#!/usr/bin/env bash
#> Запуск всех скриптов.

export PATH=$PATH:/usr/local/rle/var/bike
export PERL5LIB=/home/d.belyaev/perl5/lib/perl5
export PATH=$PATH:/usr/local/rle/bin
export SCALA_HOME=$HOME/scala-2.11.2
export PATH=$SCALA_HOME/bin:$PATH

(
set -u
set +x
set -o pipefail
cd `dirname $0`

[[ -s 01_STOP_ALL.stop ]] && echo "01_STOP_ALL.stop found! Remove it and try again.">&2 && exit 1

# запуск только при низком loadaverage или при "force"
lo="4"
loadaverage -1m -gt $lo && echo "$(date +"%F %H:%M") loadaverage too big ($(loadaverage -1m))">&2 && exit
echo "Started at $(date +"%F %H:%M")" >&2 # debug for view log



# кластеризация:
days=$(hours -d=today -shift=7days -n=-15days -days) # <--- неделю вперед (готовимся к будущему) + ~~недел назад
# ------------- считаем на даты - понедельники ---------------------:
days=`perl -M"Date::Calc qw(Day_of_Week_Abbreviation Day_of_Week)" -e'$,=" "; print grep {Day_of_Week_Abbreviation(Day_of_Week(split /\-/, $_)) eq "Mon" } @ARGV' $days`
target_dates=$days
proc=3 # count of parallel processes at time

for target_date in $target_dates; do

    jobs_start_time=`date +%s`

    for job in net_sites google ssp_sites; do

	./96_REMOVE_OLD_ALL;
	./95_REMOVE_EMPTY $job;
	./95_REMOVE_OLD_HOURS $job;
	./95_REMOVE_OLD_urls30days $job;

	tn=`href -dict="net_sites=>0, google=>3, ssp_sites=>3" -val=$job`

	# --
	target=../RESULT/10/$target_date/$job/$tn/clust_sz_1.txt 
	cmd="nice ./00_geek4 --loadaverage=$lo --want=$target"
	fork -pf=../pids/common.pids -dela=1 -n=$proc "$cmd" -wait
	
	
    done
    
    jobs_stop_time=`date +%s`

    jobs_time=$(( $jobs_stop_time - $jobs_start_time ))
    if [[ $jobs_time -gt $(( $proc*300 )) ]]; then
	# время выполнения заняло больше 5ти минут, значит - было что считать, значит новую дату считать не будем
	break
    fi

done    

#--------------------- ежедневные -------------------------
days=$(hours -d=today -n=-4days -days) # <--- стараемся успеть за N дня
target_dates=$days
proc=1 # count of parallel processes at time

for target_date in $target_dates; do
    jobs_start_time=`date +%s`
    for job in net_sites google ssp_sites; do
	tn=`href -dict="net_sites=>0, google=>3, ssp_sites=>3" -val=$job`

	# ----
	target=../RESULT/10/$target_date/$job/$tn/url_cat_diff.gz
	cmd="nice ./00_geek4 --loadaverage=$lo --want=$target"
	fork -pf=../pids/url-like.pids -dela=1 -n=$proc "$cmd" -wait


#	# ----
#	target=../RESULT/10/$target_date/$job/$tn/url_groups_diff.gz
#	./96_REMOVE_OLD_ALL;
#	./95_REMOVE_EMPTY $job;
#	./95_REMOVE_OLD_HOURS $job;
#	cmd="nice ./00_geek4 --want=$target"
#	fork -pf=../pids/common.pids -dela=3 -n=$proc "$cmd" -wait

    done
    jobs_stop_time=`date +%s`
    jobs_time=$(( $jobs_stop_time - $jobs_start_time ))
    if [[ $jobs_time -gt 120 ]]; then
	# время выполнения заняло больше 2-х минут, значит - было что считать, значит новую дату считать не будем
	break
    fi
done    

)>>"$0.log" 2>&1