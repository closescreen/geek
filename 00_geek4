#!/usr/bin/env perl
# допилить чтоб в будуще не лезло с запросами к хистори  и тогда можно вернуть кронтаб почаще
use strict;
use warnings;
use Data::Dumper;
use lib '/usr/local/rle/var/bike';
use Geek qw/ :all /;
use Getopt::Long;

my @wanted;
my $need = 'todo';
my $any = 'max';
my $deep = 1000;
my $show_targets;
my $dump_jobs;
my $force;
my $deb="";
my $set="";
my $first_job;
my $desc;
my $norun;
my $avg;
my $loadaverage;
#my $no_warn_deep;

GetOptions(
    'wanted=s' => \@wanted, # list wanted files
    'need=s' => \$need, # 'todo'|'all'
    'any=s' => \$any, # 'max'|'min'
    'deep=n' => \$deep, # recursion deep
    'show_targets' => \$show_targets, # print all 'target' keys from routes 
    'dump_jobs' => \$dump_jobs,
    'force' => \$force,
    'debug' => \$deb,
    'set=s' => \$set,
    'first_job' => \$first_job,
    'desc' => \$desc, # print descriptions
    'norun' => \$norun, # not run jobs (skip they)
    'avg' => \$avg,
    'loadaverage=i' => \$loadaverage, # при каком loadaverage 1m (до, включительно), запускать.
#    'no_warn_deep' => \$no_warn_deep, # no warn about deep recursion
) or die "Bad opt!";

@wanted = split /\s+/, join " ", @wanted;

my $lo=`loadaverage -1m`;
warn "loadaverage > $loadaverage, exit" and exit 1 if $loadaverage and $lo>$loadaverage;

my %pn = possible_need();
$pn{ $need } or die "Not allowed need='$need'. Allowed only: ".join(", ", keys %pn );

my %pa = possible_any();
$pa{ $any } or die "Not allowed any='$any'. Allowed only:".join(", ", keys %pa);

my $g = Geek->new( );
my %sm = $g->named_groups(
    day => '\d\d\d\d-\d\d-\d\d',
    hour => '\d\d\d\d-\d\d-\d\dT\d\d',
    job => '\w+',
    tn => '\d+', # typenum
);

my $res = "../RESULT/10";
my $traits_copy = "../RESULT/traits_copy";

sub Files($$){ days(from=>$+{day}, n=>-$_[0], shift=>1 )->files($_[1]) } # Files($days,TMPL) - файлы за 30 дней назад включая текущий $+{day}. Для сокращения кода.
sub ExistsFilesMinimum($$$){
 # вычисляет и просит только имеющиеся файлы из перечисленных
 # введена как принятие неизбежности того, что некоторые файлы пересчитать не могу, приходится брать что есть
 my ($days, $tmpl, $take ) = @_;
 my @all = days(from=>$+{day}, n=>-$days, shift=>1 )->files($tmpl);
 my @exists = grep { $g->test($_) } @all;
 
 if ( @exists > $take ){
    #return grep {$_} @need[0..($maximum-1)]
    my @exists_r = reverse @exists;
    return @exists_r[0..($take-1)]
 }else{
    my $deficit = $take - @exists;
    my @all_r = reverse @all;
    return @exists, @all_r[0..($deficit-1)]
 }    
}


$g->routes(
    {	target "$res/$sm{day}/$sm{job}/$sm{tn}/clust_sz_1.txt",
	need {
	    sz_vars => sub {"$res/$+{day}/$+{job}/$+{tn}/sz_vars_30days.gz"}
	},
	bash {qb "nice ./55_SZGR \"$_{job}\" \"$_{day}\""},
	note { viatmp=>0, flag=>0 },
    },
    {
	target "$res/$sm{day}/$sm{job}/$sm{tn}/sz_vars_conv.sent",
	need {
	    conv => sub{ 
		my %allow = (google=>{3=>"OK"}, ssp_sites=>{3=>"OK"}, net_sites=>{0=>"OK"}, );
		return undef unless $allow{$+{job}}{$+{tn}};
		"$res/$+{day}/$+{job}/$+{tn}/sz_vars_conv.gz" 
	    },
	},
	bash {qb "[[ -n \"$_{conv}\" ]] && nice zcat \"$_{conv}\" | ./set_sz_vars_for_bidder.pl"},
	note {check_need=>1 },
    },
    {
	target "$res/$sm{day}/$sm{job}/$sm{tn}/sz_vars_conv.gz",
	need {
	    szvars => sub{ "$res/$+{day}/$+{job}/$+{tn}/sz_vars_30days.gz" },
	},
	bash {qb "nice zcat \"$_{szvars}\" | ./53_sz_vars_conv -conf=53_sz_vars_decl.conf"},
	note {check_need=>1 },
    },
    {	target "$res/$sm{day}/$sm{job}/$sm{tn}/sz_vars_30days.gz",
	need {
	    bids => sub{ Files(30, "$res/\%F/$+{job}/$+{tn}/bids.gz") },
	    views => sub{ Files(30, "$res/\%F/net_sites/0/views.gz") },
	    tn1_totals => sub{ Files(30, "$res/\%F/$+{job}/1/total.gz") },
	    tn0_totals => sub{ Files(30, "$res/\%F/$+{job}/0/total.gz") },
	    sessions => sub{ Files(30, "$res/\%F/$+{job}/$+{tn}/sessions.gz") },
	    pzbt => sub{ Files(30, "$res/\%F/$+{job}/$+{tn}/pzbt.gz") },
	    traits30days => sub{ "$res/$+{day}/$+{job}/$+{tn}/traits30days.gz" },
	    dom_net => sub{ Files(30, "$res/%F/net_sites/0/dom_net.gz") }, # dom_net всегда - из net_sites/0
	    #dom_gr =>sub{ "$res/$+{day}/$+{job}/$+{tn}/dom_gr7days.gz" }, # меняем на any
	},
	any {
	    dom_grNdays => sub{  map { "$res/$+{day}/$+{job}/$+{tn}/dom_gr${_}days.gz" } reverse (2..7) },
	},
	
	bash { qb "nice ./51_SZVARS_30DAYS \"$_{job}\" \"$_{day}\"" },
	note { viatmp=>0, flag=>0 },
    },
    { 	target "$res/$sm{day}/$sm{job}/$sm{tn}/(?<basename>bids\.gz|views\.gz|sessions\.gz|pzbt\.gz|uidsz.gz)",
	need {
	    total => sub{ "$res/$+{day}/$+{job}/$+{tn}/total.gz" },
	    },
	cmd => sub { 
	    my %commands = (
		"views.gz"     => "nice ./37_VIEWS \"$_{job}\" \"$_{day}\"",
		"url_views.gz" => "nice ./37_VIEWS \"$_{job}\" \"$_{day}\" \"url\"",
		"sessions.gz" => "nice ./15_SESSIONS \"$_{job}\" \"$_{day}\"",
		"bids.gz" => "nice ./14_BIDS \"$_{job}\" \"$_{day}\"",
		"uidsz.gz" => "nice ./18_UIDSZ \"$_{job}\" \"$_{day}\"",
		"pzbt.gz" => "nice ./16_PZBT \"$_{job}\" \"$_{day}\"",
		
	    );
	    $commands{ $_{basename} } or warn "Not found command for $_{basename}".Dumper(\%commands) and return 0;
	},
	note { viatmp=>0, flag=>0 },	
    },
    { 	target "$res/$sm{day}/$sm{job}/$sm{tn}/traits30days.gz",
	need {
	    # Здесь уместно решить проблему пробелов в суточных трейтах на hist7:
	    # Если нет данных для текущего дня, но посчитан более поздний день, 
	    # то можно использовать этот более новый день, 
	    # но тошда нужно передавать в скрипт решение и там принимать. Гемор.
	    
	    uidsz => sub{ Files(30, "$res/%F/$+{job}/$+{tn}/uidsz.gz") }, 
	    predicted_add => sub { "$traits_copy/$+{day}/predicted_add.gz" },
	    predicted => sub { "$traits_copy/$+{day}/predict_gr_v2.gz" },
	    auditory => sub { "$traits_copy/$+{day}/auditory.gz" },
	    ctr10gr => sub { "$traits_copy/$+{day}/ctr10gr.gz" },
	    ctr11gr => sub { "$traits_copy/$+{day}/ctr11gr.gz" },
	    },
#	any {
#	    predicted_add => sub { 
#		days(from=>$+{day}, n=>3, shift=>0)->files("$traits_copy/%F/predicted_add.gz")
#		#$g->hours( from=>$+{day}, n=>24, shift=>4 )->files("$res/$+{day}/$+{job}/$+{tn}/%FT%H.gz")
#		#"$traits_copy/$+{day}/predicted_add.gz" 
#	    
#	    },	    
#	},    
	bash {qb "nice ./33_TRAITS_30DAYS \"$_{job}\" \"$_{day}\" \"$deb\" "},
	note { viatmp=>0, flag=>0 },
    },
    {	target "$res/$sm{day}/net_sites/0/dom_net.gz", # только .../net_sites/0/...
	need {
	    total => sub{ "$res/$+{day}/net_sites/0/total.gz" },
	},
	bash { qb "./35_DOM_NET %s", $_{day} },
	note { viatmp => 0, flag=>0 },
    },
    { 	target "$traits_copy/$sm{day}/(?<basename>predict_gr_v2.gz|predicted_add.gz|auditory.gz|ctr10gr.gz|ctr11gr.gz)",
	note { viatmp => 0, flag=>0 },
	perl { "hello $_{TARGET}." 
	    # можно былоб написать типо такого (не проверял), по каждый раз лезть за результатами на hist7 - распамим логи ssh
	    #bash { qb fork -pf=../pids/copy_traits.pids --single "nice ./32_COPY_TRAITS" "%s", $_{day} },	
	},
    },

    {	target "$res/$sm{day}/$sm{job}/$sm{tn}/url_groups_diff.gz",
	# need - требуется иметь:
	need {
	    url_groups => sub{ Files(2, "$res/\%F/$+{job}/$+{tn}/url_groups.gz") },
	},
	bash { qb( qq( 
	    LANG=POSIX sort -T. -t\\* -m -k1,1 -k2,2 <\( 
		zcat %s | awk -v"OFS=*" '{print \$0,"prev"}'
		\) <\(
		zcat %s | awk -v"OFS=*" '{print \$0,"curr"}'
		\) | ./27_diff 
	    ), @{$_{url_groups_ARRAY}});
	    #print $cmd;
	    #netflag sub { system "bash", '-c', $cmd }, flag=>$_{TARGET}, viatmp=>$_{TARGET};
	},
	note { check_need=>1, }, # пока для всех будем чекать
    },



    {	target "$res/$sm{day}/$sm{job}/$sm{tn}/url_groups.gz",
	# any - способ указать, что требуется хотябы один из указанного списка:
	# пока только два дня (2..2), было (1..7), потом если надо - переделать на 7
	any {
	    # here sub return code:
	    dom_grNdays => sub{  map { "$res/$+{day}/$+{job}/$+{tn}/dom_gr${_}days.gz" } reverse (2..2) },
	},
	bash {qb "nice ./25_URLGR \"$_{job}\" \"$_{day}\""},
	note { viatmp=>0, flag=>0 },
    },
    {	target "$res/$sm{day}/$sm{job}/$sm{tn}/dom_gr(?<N>\\d)days.gz",
	# д.б х-м!
	need {
	    dom_gr_current =>sub{ "$res/$+{day}/$+{job}/$+{tn}/dom_gr.txt" },
	    #dom_gr => sub{ Files( $+{N}, "$res/\%F/$+{job}/$+{tn}/dom_gr.txt") },
	    dom_gr_exists => sub{ ExistsFilesMinimum(14, "$res/%F/$+{job}/$+{tn}/dom_gr.txt", $+{N} ) },
	},     
	bash { qb "nice ./22_DOMGR7DAYS \"$_{job}\" \"$_{day}\" \"\" \"@{$_{dom_gr_exists_ARRAY}}\" \"$+{N}\" "},    
	note { viatmp=>0, flag=>0, check_need=>1, },
    },
    {	target "$res/$sm{day}/$sm{job}/$sm{tn}/dom_gr.txt",
	any {
	    domsNNdays => sub{ map {"$res/$+{day}/$+{job}/$+{tn}/doms${_}days.gz"} reverse (10..30) },
	},
	bash { qb "nice ./21_DOMGR \"$_{job}\" \"$_{day}\"" },
	note { viatmp=>0, flag=>0 },
    },
    {	target "$res/$sm{day}/$sm{job}/$sm{tn}/doms(?<NN>\\d\\d)days.gz", 
	need {
	    urlsNNdays=>sub{ "$res/$+{day}/$+{job}/$+{tn}/urls$+{NN}days.gz" },
	},
	bash { qb "nice ./20_DOM30DAYS \"$_{job}\" \"$_{day}\""},
	note { viatmp=>0, flag=>0 },
    },

    {	target "$res/$sm{day}/$sm{job}/$sm{tn}/urls(?<NN>\\d\\d)days.gz",
	need {
	    urls=>sub{ Files( $+{NN}, "$res/%F/$+{job}/$+{tn}/urls.gz") },
	},
	bash { qb "nice ./19_URLS30DAYS \"$_{job}\" \"$_{day}\"" },
	note { viatmp=>0, flag=>0 },
    },
    {
	target "$res/$sm{day}/$sm{job}/$sm{tn}/urls.gz",
	need {
	    total=>sub{ "$res/$+{day}/$+{job}/$+{tn}/total.gz" }
	},
	bash { qb "fork --single -pf=17_URLS.pids './17_URLS \"$_{job}\" \"$_{day}\"'" },
	note { viatmp=>0, flag=>0 },
    },
    {
	target "$res/$sm{day}/net_sites/0/url_vars.gz",
	need {
	    url_total=>sub{"$res/$+{day}/".'net_sites/0'."/url_total.gz"},
	},
	bash { qb "nice zcat \"$_{url_total}\" | ./52_urlvars_30days_net_sites" },
	note { check_need=>1, },
    },
    {
	target "$res/$sm{day}/(?<job>".'ssp_sites|google'.")/3/url_vars.gz",
	need {
	    bids_url_total=>sub{"$res/$+{day}/$_{job}/3/url_total.gz"},
	},
	bash { qb "nice zcat \"$_{total_by_url}\" | ./52_urlvars_30days_net_sites" },
	note { check_need=>1, },
    },

    {
	target "$res/$sm{day}/$sm{job}/$sm{tn}/(?<prefix>[a-z]*)_?total.gz", # может быть префикс типа "url" за которым следует "_"
	need {
	    hours=>sub{ $g->hours( from=>$+{day}, n=>24, shift=>4 )->files("$res/$+{day}/$+{job}/$+{tn}/%FT%H.gz") }
	},
	bash { qb "nice ./12_MERGE \"$_{job}\" \"$_{tn}\" \"$_{day}\" \"$+{prefix}\" " },
	note { viatmp => 0, flag=>0, }, # check_need отключил - попробуем делегировать mergef'у. Если много будет в логах - будем думать.    
    },
    {
	target "$res/$sm{day}/$sm{job}/$sm{tn}/(?<prefix>[a-z]*)_?$sm{hour}.gz", # может быть префикс типа "url" за которым следует "_"
	bash { qb " ./10_HOURS \"$_{job}\" \"$_{tn}\" \"$_{day}\" \"$+{prefix}\" " },
	note { viatmp => 0, flag=>0 },    
    },
#    {
#	target "$res/$sm{day}/$sm{job}/$sm{tn}/url_cat_to_send.ready",
#	need {
#	    to_send=>sub{ "$res/$+{day}/$+{job}/$+{tn}/url_cat_to_send.gz" },
#	},
#	bash {qb "(zcat $_{to_send} | ./set_urls_cats_for_bidder.pl cat_id=2) && echo \"Sent $_{to_send}\" "},
#	#bash {qb "(zcat $_{to_send} | perl -lane'1' ) && echo \"Emulating of sent $_{to_send}\" "},
#	note { check_need=>1, stdall=>"./30_sendind.log" },
#    },
#    {
#	target "$res/$sm{day}/".'google/3'."/url_cat_to_send.gz",
#	need {
#	    diff=>sub{ "$res/$+{day}/google/3/url_cat_diff.gz" },	
#	},
#	bash {qb "[[ -s \"$_{diff}\" ]] && ln -s ./`basename $_{diff}` $_{TARGET}"},
#	note { viatmp => 0, flag=>0, check_need=>1, stdall=>"./30_url_cat_to_send.log" },
#    },
#    {
#	target "$res/$sm{day}/".'ssp_sites/3'."/url_cat_to_send.gz",
#	need {
#	    diff=>sub{ "$res/$+{day}/ssp_sites/3/url_cat_diff.gz" },
#	    url_cat_dom=>sub{ "$res/$+{day}/google/3/url_cat_dom.gz" },	
#	},
#	bash {qb "nice ./30_url_cat_to_send \"@{$_{diff_ARRAY}}\" \"@{$_{url_cat_dom_ARRAY}}\" "},
#    },    
#    {
#	target "$res/$sm{day}/".'net_sites/0'."/url_cat_to_send.gz",
#	need {
#	    diff=>sub{ "$res/$+{day}/net_sites/0/url_cat_diff.gz" },
#	    url_cat_dom=>sub{ "$res/$+{day}/ssp_sites/3/url_cat_dom.gz", "$res/$+{day}/google/3/url_cat_dom.gz" },	
#	},
#	bash {qb "nice ./30_url_cat_to_send \"@{$_{diff_ARRAY}}\" \"@{$_{url_cat_dom_ARRAY}}\" "},
#    },    

    {
	target "$res/$sm{day}/$sm{job}/$sm{tn}/url_cat_diff.sent",
	need {
	    diff=>sub{ "$res/$+{day}/$+{job}/$+{tn}/".'url_cat_diff.gz' },
	    after=>sub{ 
		my %depend = (
		    ssp_sites => {3=>"$res/$+{day}/net_sites/0/".'url_cat_diff.sent'},
		    google =>    {3=>"$res/$+{day}/ssp_sites/3/".'url_cat_diff.sent'},
		);
		$depend{ $+{job} }{ $+{tn} };
	    },
	},
	bash {qb "(zcat $_{diff} | ./set_urls_cats_for_bidder.pl cat_id=2) && echo \"Sent $_{diff}\" "},
	#bash {qb "(zcat $_{diff} | perl -lane'1' ) && echo \"Emulating of sent $_{diff}\" "},
	note { check_need=>1, stdall=>"./30_sending.log" },
    },
    
    {	target "$res/$sm{day}/$sm{job}/$sm{tn}/url_cat_diff.gz",
	need {
	    url_cat => sub{ Files(2, "$res/\%F/$+{job}/$+{tn}/url_cat.gz") },
	},
	bash { qb( qq( 
	    LANG=POSIX sort -T. -t\\* -m -k1,1 <\( 
		zcat %s | awk -v"OFS=*" '{print \$0,"prev"}'
		\) <\(
		zcat %s | awk -v"OFS=*" '{print \$0,"curr"}'
		\) | ./29_diff 
	    ), @{$_{url_cat_ARRAY}});
	},
	note { check_need=>1, }, # пока для всех будем чекать
    },

    {
	target "$res/$sm{day}/$sm{job}/$sm{tn}/url_cat_dom.gz",
	need {
	    url_cat=>sub{ "$res/$+{day}/$+{job}/$+{tn}/url_cat.gz" },
	},
	bash {qb "zcat $_{url_cat} | cut -d* -f1 | perl -lane' print /([^\\/]+)/ ' | uniq "},
	note { check_need=>1,  },
    },

    {	target "$res/$sm{day}/$sm{job}/$sm{tn}/url_cat.gz", 
	need {
	    urls30days=>sub{ "$res/$+{day}/$+{job}/$+{tn}/urls30days.gz" },
	},
	bash { qb "nice ./28_URL_CAT \"$_{job}\" \"$_{day}\""},
	note { viatmp=>0, flag=>0 },
    },


);

if ($show_targets){
    local ($\,$,)=("\n","\n");
    print "Targets:", map {$_->{target}} $g->routes() and exit 0;
}


$\="\n";
my @jobs = reverse $g->match( need=>$need ,any=>$any, deep=>$deep, wanted=>\@wanted );
if ( $dump_jobs ){	print Dumper \@jobs and exit 0  }	
my @jobs_to_do = $first_job ? $jobs[0] : @jobs;

my %avg_total;
my $skipped = 0;
my $all = 0;

for my $job ( @jobs_to_do ){

#    warn "sleep...";
#    sleep 20;
#    warn "..awake";

    #die Dumper $job;
    my $file_exists = $g->test( $job->{target} ) ? "v" : "-";
    my @missing_need;
    if ( $job->{note} and $job->{note}{check_need} ){
	my %need = %{ $job->{need}||{} };
	for my $need_type ( keys %need ){
	    my @list_for_type = @{ $need{ $need_type }||[] };
	    for my $hash ( @list_for_type ){
		my $ok = $g->test($hash->{name});
		warn "Check file: $hash->{name} = ".($ok||"----(NO)") if $deb;
		push @missing_need, $hash->{name} unless $ok;
	    }
	}
    }

    if ( !$norun and @missing_need ){ 
	warn( "Skip $job->{target}: missing need files: ".join(", ", @missing_need)) if $deb;
	next;
    }
    delete $job->{note}{check_need};    
    
    if ($desc){
	use List::Util qw/min max/;
	my @desc;
	push @desc, mytime();
	push @desc, $job->{desc} ? $job->{desc} : "(without description)", " ($file_exists)";

	# работает только для данного проекта:
	if ($avg){
	    my ($t) = $job->{target}=~m|../RESULT/10/\d\d\d\d-\d\d-\d\d/(.+)|;
	    $t||="NOT FOUND";
	    $t=~s/\d\d\d\d-\d\d-\d\dT\d\d/\\d\\d\\d\\d-\\d\\d-\\d\\dT\\d\\d/; # в файлах часов замена имени
	    my $gr = "grep -P \"$t\" 00_all.time* | grep -v ')'";
	    #warn "GREP: $gr";
	    open my $grep, "$gr |" or die "can't open pipe!";
	    my @t;
	    while (<$grep>){
		#warn "FOUND $_";
		my @F = split /\s+/, $_;
		$F[3]=~s/m//; 
		push @t, $F[3];
	    }
	    my $min=min(@t); my $max=max(@t); my $avg=(($min||0) + ($max||0) )/2; 
	    
	    #die $min if $min;
	    #$rv=~s/^\s+|\s+$//g;
	    #die $rv if $rv;
	    push @desc, $max ? "min:$min, avg:$avg, max:$max" : "(unknown)";
	    if ($avg){
		$avg_total{avg} +=$avg;
		$avg_total{min} +=$min;
		$avg_total{max} +=$max;
	    }	
	    $skipped+=1 if !$max;
	    $all+=1;
	}

	push @desc, ref $job->{job} ? "perl-code" : $job->{job}; # if !ref $job->{job};
#	push @desc, "level=$job->{level}";
#	push @desc, "parents=".join( ",", grep {$_} keys %{$job->{parents}} );
	print join " ", @desc;
    }	


    my %defaults = (viatmp=>$job->{target}, flag=>$job->{target} );
    my %notes = %{ $job->{note}||{} };
    print join ",", map {"$_=$notes{$_}"} keys %notes if %notes and $deb;

    next if $norun;
    
    my ($rv, $msg) = $g->execute( 
	$job->{job},
	%defaults,
	%notes, 
	force=>$force, 
	deb=>$deb, 
	set=>$set, 
#	stdall=>"../RESULT/TEST/$job->{vars}{day}/test.log",
    );
    warn "Return value: $rv, msg=$msg" if $deb;
}    

my $minh = ($avg_total{min}||=0) ? sprintf("%.1f", $avg_total{min}/60) : "NA";
my $avgh = ($avg_total{avg}||=0) ? sprintf("%.1f", $avg_total{avg}/60) : "NA";
my $maxh = ($avg_total{max}||=0) ? sprintf("%.1f", $avg_total{max}/60) : "NA";
print "Aproximate: min:$minh hours ($avg_total{min} m), avg:$avgh hours ($avg_total{avg} m), max:$maxh ($avg_total{max} m). Skipped: $skipped / $all" if $avg;    

sub mytime{ my (undef,$mi,$h,$d,$m,$y) = localtime; $y+=1900; $m+=1; sprintf( "%d-%02d-%02d %02d:%02d", $y,$m,$d,$h,$mi) }



