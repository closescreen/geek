#!/usr/bin/env perl
# допилить чтоб в будуще не лезло с запросами к хистори  и тогда можно вернуть кронтаб почаще
use strict;
use warnings;
use Data::Dumper;
use lib '/usr/local/rle/var/bike';
use Geek qw/ :all /;
use Getopt::Long;
use Date::Calc qw(Today_and_Now Delta_DHMS);

my @wanted;
my $need = 'todo';
my $any = 'max';
my $deep = 1000;
my $show_targets;
my $dump_jobs;
my $force;
my $deb="";
my $set="";
my $first_job;
my $desc;
my $norun;
my $avg;
my $loadaverage;
#my $no_warn_deep;
my $timelog = "00_all.time.log";
my $target;
my $command;

GetOptions(
    'wanted=s' => \@wanted, # list wanted files
    'need=s' => \$need, # 'todo'|'all'
    'any=s' => \$any, # 'max'|'min'
    'deep=n' => \$deep, # recursion deep
    'show_targets' => \$show_targets, # print all 'target' keys from routes 
    'dump_jobs' => \$dump_jobs,
    'force' => \$force,
    'debug' => \$deb,
    'set=s' => \$set,
    'first_job' => \$first_job,
    'desc' => \$desc, # print descriptions
    'norun' => \$norun, # not run jobs (skip they)
    'avg' => \$avg,
    'loadaverage=i' => \$loadaverage, # при каком loadaverage 1m (до, включительно), запускать.
    'target=s' => \$target,
    'command=s' => \$command,
#    'no_warn_deep' => \$no_warn_deep, # no warn about deep recursion
) or die "Bad opt!";

if ( $command ){
 # command=file - означает: 
 @wanted = ($command); # попросить файл, указанный в опции --command
 $need = "all"; # все требуемые файлы
 $deep = 1; # глубиной рекурсии = 1, т.е. те, что непосредственно нужны для этого файла
 $norun = 1; # не выполняя
 #$deb = 1; # показать команду для фомирования файла ()
 $desc = 1; # с выводом описания
}

@wanted = split /\s+/, join " ", @wanted;

my $lo=`loadaverage -1m`;
warn "loadaverage > $loadaverage, exit" and exit 1 if $loadaverage and $lo>$loadaverage;

my %pn = possible_need();
$pn{ $need } or die "Not allowed need='$need'. Allowed only: ".join(", ", keys %pn );

my %pa = possible_any();
$pa{ $any } or die "Not allowed any='$any'. Allowed only:".join(", ", keys %pa);

my $g = Geek->new( );
my %sm = $g->named_groups(
    day => '\d\d\d\d-\d\d-\d\d',
    hour => '\d\d\d\d-\d\d-\d\dT\d\d',
    job => '\w+',
    tn => '\d+', # typenum
);

my $res = "../RESULT/10";
my $traits_copy = "../RESULT/traits_copy";

sub Files($$){ days(from=>$+{day}, n=>-$_[0], shift=>1 )->files($_[1]) } # Files($days,TMPL) - файлы за 30 дней назад включая текущий $+{day}. Для сокращения кода.
sub ExistsFilesMinimum($$$){
 # вычисляет и просит только имеющиеся файлы из перечисленных
 # введена как принятие неизбежности того, что некоторые файлы пересчитать не могу, приходится брать что есть
 my ($days, $tmpl, $take ) = @_;
 my @all = days(from=>$+{day}, n=>-$days, shift=>1 )->files($tmpl);
 my @exists = grep { $g->test($_) } @all;
 
 if ( @exists > $take ){
    #return grep {$_} @need[0..($maximum-1)]
    my @exists_r = reverse @exists;
    return @exists_r[0..($take-1)]
 }else{
    my $deficit = $take - @exists;
    my @all_r = reverse @all;
    return @exists, @all_r[0..($deficit-1)]
 }    
}


$g->routes(
    {	target "$res/$sm{day}/$sm{job}/$sm{tn}/clust_sz_1.txt",
	need {
	    sz_vars => sub {"$res/$+{day}/$+{job}/$+{tn}/sz_vars_30days.gz"}
	},
	bash {qb "nice ./55_SZGR \"$_{job}\" \"$_{day}\""},
	note { viatmp=>0, flag=>0 },
    },
    {
	target "$res/$sm{day}/$sm{job}/$sm{tn}/sz_vars_conv.sent",
	need {
	    conv => sub{ 
		my %allow = (google=>{3=>"OK"}, ssp=>{3=>"OK"}, net=>{0=>"OK"}, );
		return undef unless $allow{$+{job}}{$+{tn}};
		"$res/$+{day}/$+{job}/$+{tn}/sz_vars_conv.gz" 
	    },
	},
	bash {qb "[[ -n \"$_{conv}\" ]] && nice zcat \"$_{conv}\" | ./set_sz_vars_for_bidder.pl"},
	note {check_need=>1, timelog=>$timelog },
    },
    {
	target "$res/$sm{day}/$sm{job}/$sm{tn}/sz_vars_conv.gz",
	need {
	    szvars => sub{ "$res/$+{day}/$+{job}/$+{tn}/sz_vars_30days.gz" },
	},
	bash {qb "nice zcat \"$_{szvars}\" | ./53_sz_vars_conv -conf=53_sz_vars_decl.conf"},
	note {check_need=>1, timelog=>$timelog },
    },

    {	target "$res/$sm{day}/$sm{job}/$sm{tn}/sz_vars_30days.gz",
	need {
	    bids => sub{ Files(30, "$res/\%F/$+{job}/$+{tn}/bids.gz") },
	    views => sub{ Files(30, "$res/\%F/net/0/views.gz") },
	    tn1_totals => sub{ Files(30, "$res/\%F/$+{job}/1/total.gz") },
	    tn0_totals => sub{ Files(30, "$res/\%F/$+{job}/0/total.gz") },
	    sessions => sub{ Files(30, "$res/\%F/$+{job}/$+{tn}/sessions.gz") },
	    pzbt => sub{ Files(30, "$res/\%F/$+{job}/$+{tn}/pzbt.gz") },
	    sz_traits_30days => sub{ "$res/$+{day}/$+{job}/$+{tn}/sz_traits_30days.gz" },
	    dom_net => sub{ Files(30, "$res/%F/net/0/dom_net.gz") }, # dom_net всегда - из net/0
	    #dom_gr =>sub{ "$res/$+{day}/$+{job}/$+{tn}/dom_gr7days.gz" }, # меняем на any
	},
	any {
	    dom_grNdays => sub{  map { "$res/$+{day}/$+{job}/$+{tn}/dom_gr${_}days.gz" } reverse (2..7) },
	},
	
	bash { qb "nice ./51_SZVARS_30DAYS \"$_{job}\" \"$_{day}\"" },
	note { viatmp=>0, flag=>0, check_need=>1, },
    },
    { 	target "$res/$sm{day}/$sm{job}/$sm{tn}/(?<basename>bids\.gz|views\.gz|sessions\.gz|pzbt\.gz|uidsz.gz)",
	need {
	    total => sub{ "$res/$+{day}/$+{job}/$+{tn}/total.gz" },
	    },
	cmd => sub { 
	    my %commands = (
		"views.gz"     => "nice ./37_VIEWS \"$_{job}\" \"$_{day}\"",
		"url_views.gz" => "nice ./37_VIEWS \"$_{job}\" \"$_{day}\" \"url\"",
		"sessions.gz" => "nice ./15_SESSIONS \"$_{job}\" \"$_{day}\"",
		"bids.gz" => "nice ./14_BIDS \"$_{job}\" \"$_{day}\"",
		"uidsz.gz" => "nice ./18_UIDSZ \"$_{job}\" \"$_{day}\"",
		"pzbt.gz" => "nice ./16_PZBT \"$_{job}\" \"$_{day}\"",
		
	    );
	    $commands{ $_{basename} } or warn "Not found command for $_{basename}".Dumper(\%commands) and return 0;
	},
	note { viatmp=>0, flag=>0 },	
    },

    { 	target "$res/$sm{day}/(?<job>".'net'.")/(?<tn>".'0'.")/uidurl30days.gz",
	need {
	    total_ff => sub{ Files(30, "$res/%F/$+{job}/$+{tn}/total.gz") },
	    urls30days => sub{ "$res/$+{day}/$+{job}/$+{tn}/urls30days.gz" },
	    },
	bash {qb "nice zcat @{$_{total_ff_ARRAY}} | cut -d* -f".'1,12,13'." | uniq |
		grepf -fn <(zcat \"$_{urls30days}\" | awk -F* '\$3>10' ) -fe='\"\$F1\$F2\"' -e='\"\$F2\$F3\"' |
		LANG=POSIX sort -T. -t\\* -k1,1n -k2,2 -k3,3 -u
		# out: uid * dom * path
		" }, 
	note { check_need=>1, timelog=>$timelog, },	
    },    
    { 	target "$res/$sm{day}/(?<job>".'ssp|google'.")/(?<tn>".'3'.")/uidurl30days.gz",
	need {
	    total_ff => sub{ Files(30, "$res/%F/$+{job}/$+{tn}/total.gz") },
	    urls30days => sub{ "$res/$+{day}/$+{job}/$+{tn}/urls30days.gz" },
	    },
	bash {
	    my %fields_from_total = (ssp=>"1,9,10", google=>"1,8,9",); # у total.gz ssp\google разные поля
	    qb "nice zcat @{$_{total_ff_ARRAY}} | cut -d* -f".$fields_from_total{ $_{job} }." | uniq |
		grepf -fn <(zcat \"$_{urls30days}\" | awk -F* '\$3>10' ) -fe='\"\$F1\$F2\"' -e='\"\$F2\$F3\"' |
		LANG=POSIX sort -T. -t\\* -k1,1n -k2,2 -k3,3 -u
		# out: uid * dom * path
		" }, 
	note { check_need=>1, timelog=>$timelog, },	
    },    

    { 	target "$res/$sm{day}/$sm{job}/$sm{tn}/sz_traits_30days.gz",
	need {
	    # Здесь уместно решить проблему пробелов в суточных трейтах на hist7:
	    # Если нет данных для текущего дня, но посчитан более поздний день, 
	    # то можно использовать этот более новый день, 
	    # но тошда нужно передавать в скрипт решение и там принимать. Гемор.
	    
	    uidsz => sub{ Files(30, "$res/%F/$+{job}/$+{tn}/uidsz.gz") }, 
	    predicted_add => sub { "$traits_copy/$+{day}/predicted_add.gz" },
	    predicted => sub { "$traits_copy/$+{day}/predict_gr_v2.gz" },
	    auditory => sub { "$traits_copy/$+{day}/auditory.gz" },
	    ctr10gr => sub { "$traits_copy/$+{day}/ctr10gr.gz" },
	    ctr11gr => sub { "$traits_copy/$+{day}/ctr11gr.gz" },
	    },
	bash {qb "nice ./33_SZ_TRAITS_30DAYS \"$_{job}\" \"$_{day}\" \"$deb\" "},
	note { viatmp=>0, flag=>0 },
    },

#    {	# эксперимент с superjob:
#	target "$res/$sm{day}/$sm{job}/$sm{tn}/dom_traits_sj_30days.gz",
#	need {
#	    url_traits_sj => sub{ "$res/$+{day}/$+{job}/$+{tn}/url_traits_sj_30days.gz" },
#	},
#	bash { qb "exit" },
#	note { check_need=>1, viatmp=>0, },
#    },

    {
	target "$res/$sm{day}/$sm{job}/$sm{tn}/dom_traits_30days.gz",
	need {
	    url_traits => sub{ "$res/$+{day}/$+{job}/$+{tn}/url_traits_30days.gz" },
	},
	bash { qb "exit" },
	note { check_need=>1, viatmp=>0, },
    },

    { 	target "$res/$sm{day}/$sm{job}/$sm{tn}/url_traits_30days.gz",
	need {
	    uidurl30days => sub{ "$res/$+{day}/$+{job}/$+{tn}/uidurl30days.gz" },
	    predicted_add => sub{ "$traits_copy/$+{day}/predicted_add.gz" },
	    buyers => sub{ "$traits_copy/$+{day}/filtered_traits.txt.gz" },
	    },
	bash {qb "nice ./34_url_traits \"$_{day}\" \"$_{job}\" \"$_{tn}\" \"$_{uidurl30days}\" \"$_{predicted_add}\" \"$_{buyers}\" \"$_{TARGET}\" "},
	note { check_need=>1, timelog=>$timelog,  },
    },
    {	target "$traits_copy/$sm{day}/filtered_traits.txt.gz",
	bash {qb "exit"}
    
    },

#    { 	# reseach - эксперимент, потом удалить
#	target "$res/$sm{day}/$sm{job}/$sm{tn}/url_traits_sj_30days.gz",
#	need {
#	    uidurl30days => sub{ "$res/$+{day}/$+{job}/$+{tn}/uidurl30days.gz" },
#	    superjob => sub{ "$res/$+{day}/$+{job}/$+{tn}/superjob30days.gz" }, #<----  данные с суперджоба uid*m/f делаются скриптом на hist7 в home, а вызывыется по ssh руками
#	    buyers => sub{ "$traits_copy/$+{day}/filtered_traits.txt.gz" },
#	    },
#	bash {qb "nice ./34_url_traits \"$_{day}\" \"$_{job}\" \"$_{tn}\" \"$_{uidurl30days}\" \"$_{superjob}\" \"$_{buyers}\" \"$_{TARGET}\" "},
#	note { check_need=>1, timelog=>$timelog,  },
#    },

    
    {	target "$res/$sm{day}/net/0/dom_net.gz", # только .../net/0/...
	need {
	    total => sub{ "$res/$+{day}/net/0/total.gz" },
	},
	bash { qb "./35_DOM_NET %s", $_{day} },
	note { viatmp => 0, flag=>0 },
    },
    { 	target "$traits_copy/$sm{day}/(?<basename>predict_gr_v2.gz|predicted_add.gz|auditory.gz|ctr10gr.gz|ctr11gr.gz)",
	note { viatmp => 0, flag=>0 },
	perl { "hello $_{TARGET}." 
	    # можно былоб написать типо такого (не проверял), по каждый раз лезть за результатами на hist7 - распамим логи ssh
	    #bash { qb fork -pf=../pids/copy_traits.pids --single "nice ./32_COPY_TRAITS" "%s", $_{day} },	
	},
    },

    {	target "$res/$sm{day}/$sm{job}/$sm{tn}/url_groups_diff.gz",
	# need - требуется иметь:
	need {
	    url_groups => sub{ Files(2, "$res/\%F/$+{job}/$+{tn}/url_groups.gz") },
	},
	bash { qb( qq( 
	    LANG=POSIX sort -T. -t\\* -m -k1,1 -k2,2 <\( 
		zcat %s | awk -v"OFS=*" '{print \$0,"prev"}'
		\) <\(
		zcat %s | awk -v"OFS=*" '{print \$0,"curr"}'
		\) | ./27_diff 
	    ), @{$_{url_groups_ARRAY}});
	    #print $cmd;
	    #netflag sub { system "bash", '-c', $cmd }, flag=>$_{TARGET}, viatmp=>$_{TARGET};
	},
	note { check_need=>1, timelog=>$timelog }, # пока для всех будем чекать
    },



    {	target "$res/$sm{day}/$sm{job}/$sm{tn}/url_groups.gz",
	# any - способ указать, что требуется хотябы один из указанного списка:
	# пока только два дня (2..2), было (1..7), потом если надо - переделать на 7
	any {
	    # here sub return code:
	    dom_grNdays => sub{  map { "$res/$+{day}/$+{job}/$+{tn}/dom_gr${_}days.gz" } reverse (2..2) },
	},
	bash {qb "nice ./25_URLGR \"$_{job}\" \"$_{day}\""},
	note { viatmp=>0, flag=>0 },
    },
    {	target "$res/$sm{day}/$sm{job}/$sm{tn}/dom_gr(?<N>\\d)days.gz",
	# д.б х-м!
	need {
	    dom_gr_current =>sub{ "$res/$+{day}/$+{job}/$+{tn}/dom_gr.txt" },
	    #dom_gr => sub{ Files( $+{N}, "$res/\%F/$+{job}/$+{tn}/dom_gr.txt") },
	    dom_gr_exists => sub{ ExistsFilesMinimum(14, "$res/%F/$+{job}/$+{tn}/dom_gr.txt", $+{N} ) },
	},     
	bash { qb "nice ./22_DOMGR7DAYS \"$_{job}\" \"$_{day}\" \"\" \"@{$_{dom_gr_exists_ARRAY}}\" \"$+{N}\" "},    
	note { viatmp=>0, flag=>0, check_need=>1, timelog=>$timelog },
    },
    {	target "$res/$sm{day}/$sm{job}/$sm{tn}/dom_gr.txt",
	any {
	    domsNNdays => sub{ map {"$res/$+{day}/$+{job}/$+{tn}/doms${_}days.gz"} reverse (10..30) },
	},
	bash { qb "nice ./21_DOMGR \"$_{job}\" \"$_{day}\"" },
	note { viatmp=>0, flag=>0 },
    },
    {	target "$res/$sm{day}/$sm{job}/$sm{tn}/doms(?<NN>\\d\\d)days.gz", 
	need {
	    urlsNNdays=>sub{ "$res/$+{day}/$+{job}/$+{tn}/urls$+{NN}days.gz" },
	},
	bash { qb "nice ./20_DOM30DAYS \"$_{job}\" \"$_{day}\""},
	note { viatmp=>0, flag=>0 },
    },

    {	target "$res/$sm{day}/$sm{job}/$sm{tn}/urls(?<NN>\\d\\d)days.gz",
	need {
	    urls=>sub{ Files( $+{NN}, "$res/%F/$+{job}/$+{tn}/urls.gz") },
	},
	bash { qb "nice ./19_URLS30DAYS \"$_{job}\" \"$_{day}\"" },
	note { viatmp=>0, flag=>0 },
    },
    {
	target "$res/$sm{day}/$sm{job}/$sm{tn}/urls.gz",
	need {
	    total=>sub{ "$res/$+{day}/$+{job}/$+{tn}/total.gz" }
	},
	bash { qb "fork -wait --single -pf=../pids/urls.pids './17_URLS \"$_{job}\" \"$_{day}\"'" },
	note { viatmp=>0, flag=>0, runtime_need=>"freemem -gt 15", },
    },
    {
	target "$res/$sm{day}/$sm{job}/$sm{tn}/urlvars_diff.sent",
	need {
	    total=>sub{ 
		my $diff = "$res/$+{day}/$+{job}/$+{tn}/urlvars_diff.gz";
		my $init = "$res/$+{day}/$+{job}/$+{tn}/urlvars_diff_INIT.gz";
		my $old_diff = [ Files( 8, "$res/%F/$+{job}/$+{tn}/urlvars_diff.gz" ) ]->[0];
		warn "$diff $init $old_diff";
		
		if ( !-s $diff and !-s $init and ! -s $old_diff ){ $init }
		elsif( ! -s $diff and ! -s $init and -s $old_diff ){ $diff  }
		elsif( -s $diff or -s $init ){ grep { -s } ( $diff, $init ) }
		
	    },
	},
	bash { qb "zcat $_{total} | ./set_urlvars_for_bidder.pl && echo \"Sent $_{total}\"" },
	note { check_need=>1, timelog=>$timelog },
    },    
    {
	target "$res/$sm{day}/$sm{job}/$sm{tn}/urlvars_diff_INIT.gz",
	need {
	    total=>sub{ "$res/$+{day}/$+{job}/$+{tn}/url_vars_30days.gz" },
	},
	bash { qb "zcat \"$_{total}\" | ./52_urlvars_diff" },
	note { check_need=>1, timelog=>$timelog },
    },    
    {
	target "$res/$sm{day}/$sm{job}/$sm{tn}/urlvars_diff.gz",
	need {
	    total=>sub{ 
		my @ff = Files( 8, "$res/%F/$+{job}/$+{tn}/url_vars_30days.gz" );
		@ff = @ff[0,-1]; # первый и последний файл из этого списка
		return @ff;
	    }
	},
	bash { qb "
	    LANG=POSIX sort -t\\* -m <(zcat \"$_{total_ARRAY}[0]\" | perl -lne'print \$_.\"*P\"')  <(zcat \"$_{total_ARRAY}[1]\" | perl -lne'print \$_.\"*C\"') -k1,1 -k2,2 |
	    ./52_urlvars_diff" },
	note { check_need=>1, timelog=>$timelog },
    },

#    {	# url_vars по superjob: эксперимент
#	target "$res/$sm{day}/(?<job>".'net'.")/(?<tn>".'0'.")/url_vars_sj_(?<N>\\d+)days.gz",
#	need {
#	    url_total=>sub{ Files( $+{N}, "$res/%F/$+{job}/$+{tn}/url_total.gz") },
#	    url_traits_sj_30days => sub{ "$res/$+{day}/$+{job}/$+{tn}/url_traits_sj_30days.gz" },
#	    dom_traits_sj_30days => sub{ "$res/$+{day}/$+{job}/$+{tn}/dom_traits_sj_30days.gz" },
#	},
#	bash { qb "nice ./52_urlvars_30days_net \"$_{url_total}\" \"$_{url_traits_sj_30days}\" \"$_{dom_traits_sj_30days}\"" },
#	note { check_need=>1, timelog=>$timelog },
#    },
    
    {
	target "$res/$sm{day}/$sm{job}/$sm{tn}/url_vars_30days.gz",
	need {
	    url_total=>sub{ 
		my %stem = (net=>"url_total", ssp=>"url_total",google=>"url_total");
		return Files( 30, "$res/%F/$+{job}/$+{tn}/$stem{$+{job}}.gz");
	    },
	    url_traits_30days => sub{ "$res/$+{day}/$+{job}/$+{tn}/url_traits_30days.gz" },
	    dom_traits_30days => sub{ "$res/$+{day}/$+{job}/$+{tn}/dom_traits_30days.gz" },
	},
	bash { qb "nice ./52_urlvars_30days_$_{job} \"$_{url_total}\" \"$_{url_traits_30days}\" \"$_{dom_traits_30days}\"" },
	note { check_need=>1, timelog=>$timelog },
    },


    {
	target "$res/$sm{day}/$sm{job}/$sm{tn}/(?<prefix>url)?_?total.gz", # может быть префикс типа "url" за которым следует "_"
	need {
	    hours=>sub{
		my @hours;
		push @hours, $g->hours( from=>$+{day}, n=>24, shift=>4 )->files( "$res/$+{day}/$+{job}/$+{tn}/%FT%H.gz" );
		if ( $+{tn} eq "3" and $+{prefix}||"" eq "url" ){
		    push @hours, $g->hours( from=>$+{day}, n=>24, shift=>4 )->files( "$res/$+{day}/$+{job}/".'0'."/%FT%H.gz" );
		}
		@hours;
	    }
	},
	bash { qb "nice ./12_MERGE \"$_{job}\" \"$_{tn}\" \"$_{day}\" \"".($+{prefix}||"")."\" " },
	note { viatmp => 0, flag=>0, timelog=>$timelog, check_need=>0, },     
    },

#    {  # вместо url_total_join теперь 3/url_total
#	target "$res/$sm{day}/(?<job>".'google|ssp'.")/3/url_total_join.gz", 
#	need {
#	    url_total_tn0=>sub{ "$res/$+{day}/$+{job}/0/url_total.gz" },
#	    url_total_tn3=>sub{ "$res/$+{day}/$+{job}/3/url_total.gz" },
#	},
#	bash { qb "
#	    zcat \"$_{url_total_tn3}\" | # dom * path * cnt_bids * sum_exppr
#	    awk -F* -vOFS=* '{print \$1\$2,\$0}' | # (+)url * dom * path * cnt_bids * sum_exppr
#	    addf -df=<( zcat \"$_{url_total_tn0}\" | awk -F* -vOFS=* '{print \$1\$2,\$0}' ) -dadd=4,5,6 | # url*tn0cnt*tn0sumexppr*tn0sumwinpr*dom*path*tn3cnt*tn3sumexppr
#	    awk -F* -vOFS=* '{print \$5,\$6,\$7,\$8,\$2,\$3,\$4}'   
#	    # dom * path * tn3_cnt(bids) * tn3_sum(exppr) * tn0_cnt(exp) * tn0_sum(exppr) * tn0_sum(winpr)
#	" },
#	note { check_need=>1, timelog=>$timelog },     
#    },
    
    {
	target "$res/$sm{day}/$sm{job}/$sm{tn}/(?<prefix>[a-z]*)_?$sm{hour}.gz", # может быть префикс типа "url" за которым следует "_"
	bash { qb " ./10_HOURS \"$_{job}\" \"$_{tn}\" \"$_{day}\" \"$+{prefix}\" " },
	note { viatmp => 0, flag=>0 },    
    },

    {
	target "$res/$sm{day}/$sm{job}/$sm{tn}/url_cat_diff.sent",
	need {
	    diff=>sub{ "$res/$+{day}/$+{job}/$+{tn}/".'url_cat_diff.gz' },
	    after=>sub{ 
		my %depend = (
		    ssp => {3=>"$res/$+{day}/net/0/".'url_cat_diff.sent'},
		    google =>    {3=>"$res/$+{day}/ssp/3/".'url_cat_diff.sent'},
		);
		$depend{ $+{job} }{ $+{tn} };
	    },
	},
	bash {qb "(zcat $_{diff} | ./set_urls_cats_for_bidder.pl cat_id=2) && echo \"Sent $_{diff}\" "},
	#bash {qb "(zcat $_{diff} | perl -lane'1' ) && echo \"Emulating of sent $_{diff}\" "},
	note { check_need=>1, stdall=>"./30_sending.log", timelog=>$timelog },
    },
    
    {	target "$res/$sm{day}/$sm{job}/$sm{tn}/url_cat_diff.gz",
	need {
	    url_cat => sub{ Files(2, "$res/\%F/$+{job}/$+{tn}/url_cat.gz") },
	},
	bash { qb( qq( 
	    LANG=POSIX sort -T. -t\\* -m -k1,1 <\( 
		zcat %s | awk -v"OFS=*" '{print \$0,"prev"}'
		\) <\(
		zcat %s | awk -v"OFS=*" '{print \$0,"curr"}'
		\) | ./29_diff 
	    ), @{$_{url_cat_ARRAY}});
	},
	note { check_need=>1, timelog=>$timelog }, # пока для всех будем чекать
    },

    {
	target "$res/$sm{day}/$sm{job}/$sm{tn}/url_cat_dom.gz",
	need {
	    url_cat=>sub{ "$res/$+{day}/$+{job}/$+{tn}/url_cat.gz" },
	},
	bash {qb "zcat $_{url_cat} | cut -d* -f1 | perl -lane' print /([^\\/]+)/ ' | uniq "},
	note { check_need=>1, timelog=>$timelog  },
    },

    {	target "$res/$sm{day}/$sm{job}/$sm{tn}/url_cat.gz", 
	need {
	    urls30days=>sub{ "$res/$+{day}/$+{job}/$+{tn}/urls30days.gz" },
	},
	bash { qb "nice ./28_URL_CAT \"$_{job}\" \"$_{day}\""},
	note { viatmp=>0, flag=>0, check_need=>1 },
    },
    
# не нужно?
#    {	target "$res/$sm{day}/".'net/0/'."dom_total.gz",
#	need {
#	    url_total=>sub{"$res/$+{day}/net/0/url_total.gz"},
#	},
#	bash { qb "nice zcat \"$_{url_total}\" | ./40_dom_total_net_tn0"},
#	note { check_need=>1, timelog=>$timelog },
#    },


);

if ($show_targets){
    local ($\,$,)=("\n","\n");
    #die Dumper grep { $_->{target} and $_->{target}=~/url_total/ } $g->routes();
    print "Targets:", map {$_->{target}} $g->routes() and exit 0;
}

if ($target){
    no warnings;
    exec qq( grep -H -m10 -n --color=auto -A20 -P "target.*?$target" 00_geek4 );
}

$\="\n";
my @jobs = reverse $g->match( need=>$need ,any=>$any, deep=>$deep, wanted=>\@wanted );
if ( $dump_jobs ){	print Dumper \@jobs and exit 0  }	
my @jobs_to_do = $first_job ? $jobs[0] : @jobs;

my %avg_total;
my $avg_skiped = 0;
#my $skiped_jobs = 0;
my $all = 0;

for my $job ( @jobs_to_do ){

#    warn "sleep...";
#    sleep 20;
#    warn "..awake";

#    die Dumper $job;
    my $file_exists = $g->test( $job->{target} ) ? "v" : "-";
    my @missing_need;
    if ( $job->{note} and $job->{note}{check_need} ){
	my %need = %{ $job->{need}||{} };
	for my $need_type ( keys %need ){
	    my @list_for_type = @{ $need{ $need_type }||[] };
	    for my $hash ( @list_for_type ){
		my $ok = $g->test($hash->{name});
		warn "Check file: $hash->{name} = ".($ok||"----(NO)") if $deb;
		push @missing_need, $hash->{name} unless $ok;
	    }
	}
    }

    if ( !$norun and @missing_need ){ 
	warn( "Skip $job->{target}: missing need files: ".join(", ", @missing_need)) if $deb;
	#$skiped_jobs+=1;
	next;
    }
    delete $job->{note}{check_need};
    
    my @runtime_checks;
    if ( $job->{note} and my $rn = $job->{note}{runtime_need} ){
	$rn = [ $rn ] if !ref $rn;
	if ( ref $rn eq "ARRAY" ){
	    for my $test ( @$rn ){
		$test or warn "Empty test, skip. ".Dumper($rn);
		# test must be a string for bash:
		my $status = system($test);
		if ($status>0){
		    push @runtime_checks, "test:'$test', status:$status";
		}else{
		    warn "Test:$test status:$status - ok" if $deb;
		}
	    }
	}else{
	    warn "runtime_need must be a array-ref or string (bash-command)!, skip checking. ".Dumper($rn);
	}
    }
    if (@runtime_checks){
	warn "Fails runtime check(s): @runtime_checks";
	next;
    }
    delete $job->{note}{runtime_need};
    
    my %timelog;
    if ( $job->{note} and $timelog{file}=$job->{note}{timelog}){
	$timelog{start}=[Today_and_Now] and $timelog{start_sec}=time and delete $job->{note}{timelog}
    }
    
    if ($desc){
	use List::Util qw/min max/;
	my @desc;
	push @desc, mytime();
	push @desc, $job->{desc} ? $job->{desc} : "(without description)", " ($file_exists)";

	# работает только для данного проекта:
	if ($avg){
	    my ($t) = $job->{target}=~m|../RESULT/10/\d\d\d\d-\d\d-\d\d/(.+)|;
	    $t||="NOT FOUND";
	    $t=~s/\d\d\d\d-\d\d-\d\dT\d\d/\\d\\d\\d\\d-\\d\\d-\\d\\dT\\d\\d/; # в файлах часов замена имени
	    my $gr = "grep -P \"$t\" 00_all.time* | grep -v ')'";
	    #warn "GREP: $gr";
	    open my $grep, "$gr |" or die "can't open pipe!";
	    my @t;
	    while (<$grep>){
		#warn "FOUND $_";
		my @F = split /\s+/, $_;
		$F[3]=~s/m//; 
		push @t, $F[3];
	    }
	    my $min=min(@t); my $max=max(@t); my $avg=(($min||0) + ($max||0) )/2; 
	    
	    #die $min if $min;
	    #$rv=~s/^\s+|\s+$//g;
	    #die $rv if $rv;
	    push @desc, $max ? "min:$min, avg:$avg, max:$max" : "(unknown)";
	    if ($avg){
		$avg_total{avg} +=$avg;
		$avg_total{min} +=$min;
		$avg_total{max} +=$max;
	    }	
	    $avg_skiped+=1 if !$max;
	    $all+=1;
	}

	push @desc, ref $job->{job} ? "perl-code" : $job->{job}; # if !ref $job->{job};
#	push @desc, "level=$job->{level}";
#	push @desc, "parents=".join( ",", grep {$_} keys %{$job->{parents}} );
	#unshift @desc, "==>"; # поломает статистику, наверное в логе
	print join " ", @desc;
    }	


    my %defaults = (viatmp=>$job->{target}, flag=>$job->{target} );
    my %notes = %{ $job->{note}||{} };
    print join ",", map {"$_=$notes{$_}"} keys %notes if %notes and $deb;

    next if $norun;
    
    my ($rv, $msg) = $g->execute( 
	$job->{job},
	%defaults,
	%notes, 
	force=>$force, 
	deb=>$deb, 
	set=>$set, 
#	stdall=>"../RESULT/TEST/$job->{vars}{day}/test.log",
    );
    warn "Return value: $rv, msg=$msg" if $deb;
    
    if ( $rv and $timelog{file} and $timelog{start} and $timelog{end}=[Today_and_Now] and $timelog{end_sec}=time ){
        my $min = int( ($timelog{end_sec}-$timelog{start_sec})/60);
	my $string = sprintf("%s %d-%02d-%02dT%02d:%02d %d-%02d-%02dT%02d:%02d %dm", $job->{target}, @{ $timelog{start} }[0..4], @{ $timelog{end} }[0..4], $min );
	local $|=1;
	open my $log, ">>$timelog{file}" or die "can't open $timelog{file}: $!";
	print $log "$string";
    }
}    

my $minh = ($avg_total{min}||=0) ? sprintf("%.1f", $avg_total{min}/60) : "NA";
my $avgh = ($avg_total{avg}||=0) ? sprintf("%.1f", $avg_total{avg}/60) : "NA";
my $maxh = ($avg_total{max}||=0) ? sprintf("%.1f", $avg_total{max}/60) : "NA";
print "Aproximate: min:$minh hours ($avg_total{min} m), avg:$avgh hours ($avg_total{avg} m), max:$maxh ($avg_total{max} m). skiped: $avg_skiped / $all" if $avg;    

sub mytime{ my (undef,$mi,$h,$d,$m,$y) = localtime; $y+=1900; $m+=1; sprintf( "%d-%02d-%02d %02d:%02d", $y,$m,$d,$h,$mi) }



